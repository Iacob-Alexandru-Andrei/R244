{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhgpM92PMCd-"
      },
      "source": [
        "# Flower Quickstart (Simulation with TensorFlow/Keras)\n",
        "\n",
        "Welcome to Flower, a friendly federated learning framework!\n",
        "\n",
        "In this notebook, we'll simulate a federated learning system with 100 clients. The clients will use TensorFlow/Keras to define model training and evaluation. Let's start by installing Flower Nightly, published as `flwr-nightly` on PyPI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXG21C3dLj6i",
        "outputId": "f60586a0-3fc5-4801-919d-01977224a39b"
      },
      "outputs": [],
      "source": [
        "# !pip install git+https://github.com/adap/flower.git@release/0.17#egg=flwr[\"simulation\"]  # For a specific branch (release/0.17) w/ extra (\"simulation\")\n",
        "# # !pip install -U flwr[\"simulation\"]  # Once 0.17.1 is released"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQk9ZzCBMf9r"
      },
      "source": [
        "Next, we import the required dependencies. The most important imports are Flower (`flwr`) and TensorFlow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oKvjox6uMkhj"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'src'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_5756/3420319341.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./src\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msimulation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstart_simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/r244_alex/R244_Project/src/CBO_Flower_Simulation/simulation/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_ray_installed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCBO_app\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mCBO_app\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstart_simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/r244_alex/R244_Project/src/CBO_Flower_Simulation/simulation/CBO_app.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcbo_server\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_fl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_init_defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcbo_server\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStrategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/r244_alex/R244_Project/src/CBO_Flower_Simulation/cbo_server/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstart_bo_server\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstart_bo_server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleClientManager\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSimpleClientManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHistory\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mHistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/r244_alex/R244_Project/src/CBO_Flower_Simulation/cbo_server/app.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleClientManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBoServer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFedAvg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStrategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/r244_alex/R244_Project/src/CBO_Flower_Simulation/cbo_server/server.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"-1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfairbo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopt_adam_max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfairbo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExactGPModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "\n",
        "# Make TensorFlow logs less verbose\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "import flwr as fl\n",
        "\n",
        "\n",
        "from simulation import start_simulation\n",
        "import torch\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30pJWfaTM_MC"
      },
      "source": [
        "With that out of the way, let's move on to the interesting bits. Federated learning systems consist of a server and multiple clients. In Flower, we create clients by implementing subclasses of `flwr.client.Client` or `flwr.client.NumPyClient`. We use `NumPyClient` in this tutorial because it is easier to implement and requires us to write less boilerplate.\n",
        "\n",
        "To implement the Flower client, we create a subclass of `flwr.client.NumPyClient` and implement the three methods `get_parameters`, `fit`, and `evaluate`:\n",
        "\n",
        "- `get_parameters`: Return the current local model parameters\n",
        "- `fit`: Receive model parameters from the server, train the model parameters on the local data, and return the (updated) model parameters to the server \n",
        "- `evaluate`: Received model parameters from the server, evaluate the model parameters on the local data, and return the evaluation result to the server\n",
        "\n",
        "We mentioned that our clients will use TensorFlow/Keras for the model training and evaluation. Keras models provide methods that make the implementation staightforward: we can update the local model with server-provides parameters through `model.set_weights`, we can train/evaluate the model through `fit/evaluate`, and we can get the updated model parameters through `model.get_weights`.\n",
        "\n",
        "Let's see a simple implementation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vE3mqBs0NHZi"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, data, y_train, x_val, y_val) -> None:\n",
        "        # self.model = model\n",
        "        # self.x_train, self.y_train = x_train, y_train\n",
        "        # self.x_val, self.y_val = x_train, y_train\n",
        "        self.data = data\n",
        "\n",
        "    def get_parameters(self):\n",
        "        return np.zeros(1)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # self.model.set_weights(parameters)\n",
        "        # self.model.fit(self.x_train, self.y_train, epochs=1, verbose=2)\n",
        "        return np.zeros(1), 0, {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        learning_rate = torch.exp(config['h0']).item()\n",
        "        learning_rate_decay = torch.exp(config['h1']).item()\n",
        "        l2_regular = torch.exp(config['h2']).item()\n",
        "        s = int(config['seed'])\n",
        "\n",
        "        config = tf.ConfigProto()\n",
        "        tf.disable_v2_behavior()\n",
        "        tf.reset_default_graph()\n",
        "        tf.set_random_seed(s)\n",
        "        np.random.seed(s)\n",
        "        \n",
        "        num_classes = 10\n",
        "        epochs = 20\n",
        "        X_train, X_test, Y_train, Y_test = self.data[s][0], self.data[s][1], self.data[s][2], self.data[s][3]\n",
        "\n",
        "        X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "        X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "        X_train = X_train.astype('float32')\n",
        "        X_test = X_test.astype('float32')\n",
        "        X_train = 1 - X_train\n",
        "        X_test = 1 - X_test\n",
        "\n",
        "        dropout_rate = 0.0\n",
        "\n",
        "        batch_size = 32\n",
        "        conv_filters = 16\n",
        "        dense_units = 8\n",
        "\n",
        "        num_conv_layers = 2\n",
        "        kernel_size = 3\n",
        "        pool_size = 3\n",
        "\n",
        "        # build the CNN model using Keras\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(conv_filters, (kernel_size, kernel_size), padding='same',\n",
        "                         input_shape=X_train.shape[1:], kernel_regularizer=regularizers.l2(l2_regular)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_units, kernel_regularizer=regularizers.l2(l2_regular)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Dense(num_classes))\n",
        "        model.add(Activation('softmax'))\n",
        "\n",
        "        opt = RMSprop(lr=learning_rate, decay=learning_rate_decay)\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=opt,\n",
        "                      metrics=['accuracy'])\n",
        "        #\n",
        "        history = model.fit(X_train, Y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      validation_data=(X_test, Y_test),\n",
        "                      shuffle=True, verbose=0)\n",
        "        val_acc = max(history.history['val_acc'])  \n",
        "      \n",
        "        return 0.0, s, {\"accuracy\": val_acc}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our class `FlowerClient` defines how local training/evaluation will be performed and allows Flower to call the local training/evaluation through `fit` and `evaluate`. Each instance of `FlowerClient` represents a *single client* in our federated learning system. Federated learning systems have multiple clients (otherwise there's not much to federate, is there?), so each client will be represented by its own instance of `FlowerClient`. If we have, for example, three clients in our workload, we'd have three instances of `FlowerClient`. Flower calls `FlowerClient.fit` on the respective instance when the server selects a particular client for training (and `FlowerClient.evaluate` for evaluation).\n",
        "\n",
        "In this notebook, we want to simulate a federated learning system with 100 clients on a single machine. This means that the server and all 100 clients will live on a single machine and share resources such as CPU, GPU, and memory. Having 100 clients would mean having 100 instances of `FlowerClient` im memory. Doing this on a single machine can quickly exhaust the available memory resources, even if only a subset of these clients participates in a single round of federated learning.\n",
        "\n",
        "In addition to the regular capabilities where server and clients run on multiple machines, Flower therefore provides special simulation capabilities that create `FlowerClient` instances only when they are actually necessary for training or evaluation. To enable the Flower framework to create clients when necessary, we need to implement a function called `client_fn` that creates a `FlowerClient` instance on demand. Flower calls `client_fn` whenever it needs an instance of one particular client to call `fit` or `evaluate` (those instances are usually discarded after use). Clients are identified by a client ID, or short `cid`. The `cid` can be used, for example, to load different local data partitions for each client:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtlBA2OFO0tf"
      },
      "outputs": [],
      "source": [
        "def get_client_fn():\n",
        "    data = pickle.load(open(\"/home/ubuntu/r244_alex/R244_Project/src/examples_code/quickstart_simulation/data/emnist_data_mixed.pkl\", \"rb\"))\n",
        "    def client_fn(cid: str) -> fl.client.Client:\n",
        "        nonlocal data\n",
        "        # Create model\n",
        "        # model = tf.keras.models.Sequential(\n",
        "        #     [\n",
        "        #         tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        #         tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "        #         tf.keras.layers.Dropout(0.2),\n",
        "        #         tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
        "        #     ]\n",
        "        # )\n",
        "        # model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "        # # Load data partition (divide MNIST into NUM_CLIENTS distinct partitions)\n",
        "        # (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
        "        # partition_size = math.floor(len(x_train) / NUM_CLIENTS)\n",
        "        # idx_from, idx_to = int(cid) * partition_size, (int(cid) + 1) * partition_size\n",
        "        # x_train_cid = x_train[idx_from:idx_to] / 255.0\n",
        "        # y_train_cid = y_train[idx_from:idx_to]\n",
        "\n",
        "        # # Use 10% of the client's training data for validation\n",
        "        # split_idx = math.floor(len(x_train) * 0.9)\n",
        "        # x_train_cid, y_train_cid = x_train_cid[:split_idx], y_train_cid[:split_idx]\n",
        "        # x_val_cid, y_val_cid = x_train_cid[split_idx:], y_train_cid[split_idx:]\n",
        "\n",
        "        # Create and return client\n",
        "        return FlowerClient(0, data, 0, 0, 0)\n",
        "    return client_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 1, {'accuracy': 0.82758623})"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client_fn = get_client_fn()\n",
        "NUM_CLIENTS=10\n",
        "\n",
        "\n",
        "client_fn(\"123\").evaluate(None,{\n",
        "    \"h0\":torch.Tensor([np.log(0.001)]),\n",
        "    \"h1\":torch.Tensor([np.log(0.001)]),\n",
        "    \"h2\":torch.Tensor([np.log(0.001)]), \n",
        "    \"seed\":1,\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SVawWSgO48Q"
      },
      "source": [
        "We now have `FlowerClient` which defines client-side training and evaluation and `client_fn` which allows Flower to create `FlowerClient` instances whenever it needs to call `fit` or `evaluate` on one particular client. The last step is to start the actual simulation using `flwr.simulation.start_simulation`. \n",
        "\n",
        "The function `start_simulation` accepts a number of arguments, amongst them the `client_fn` used to create `FlowerClient` instances, the number of clients to simulate `num_clients`, the number of rounds `num_rounds`, and the strategy. The strategy encapsulates the federated learning approach/algorithm, for example, *Federated Averaging* (FedAvg).\n",
        "\n",
        "Flower comes with a number of built-in strategies, but we can also use our own strategy implementations to customize nearly all aspects of the federated learning approach. For this example, we use the built-in `FedAvg` implementation and customize it using a few basic parameters. The last step is the actual call to `start_simulation` which - you guessed it - actually starts the simulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Yxjysu5PM-A",
        "outputId": "cf5f1bab-0d94-4876-bd6a-cdb0652826ff"
      },
      "outputs": [],
      "source": [
        "client_fn = get_client_fn()\n",
        "# Create FedAvg strategy\n",
        "strategy=fl.server.strategy.FedAvg(\n",
        "        fraction_fit=1.0,  # Sample 10% of available clients for training\n",
        "        fraction_eval=1.0,  # Sample 5% of available clients for evaluation\n",
        "        min_fit_clients=NUM_CLIENTS,  # Never sample less than 10 clients for training\n",
        "        min_eval_clients=NUM_CLIENTS,  # Never sample less than 5 clients for evaluation\n",
        "        min_available_clients=NUM_CLIENTS,  # Wait until at least 75 clients are available\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    num_rounds=1,\n",
        "    strategy=strategy,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Congratulations! With that, you built a Flower client, customized it's instantiation through the `client_fn`, customized the server-side execution through a `FedAvg` strategy configured for this workload, and started a simulation with 100 clients (each holding their own individual partition of the MNIST dataset).\n",
        "\n",
        "Next, you can continue to explore more advanced Flower topics:\n",
        "\n",
        "- Deploy server and clients on different machines using `start_server` and `start_client`\n",
        "- Customize the server-side execution through custom strategies\n",
        "- Customize the client-side exectution through `config` dictionaries"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "flower.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "1c67b87cde3b5052ebeac6b38fcea53a0f483c4f2759537c54ed26c372560850"
    },
    "kernelspec": {
      "display_name": "Python 3.7.12 64-bit ('alex': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
